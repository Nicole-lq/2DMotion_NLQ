---
title: 'Tarea1: Análisis de Datos de Calidad del Aire'
output:
  html_document:
    air_print: paged
  pair_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Pasos iniciales: Instalación de paquetes y carga de librerías

Se procede con la instalación de paquetes y librerías que serán necesarias para el desarrollo de este trabajo, usando el comando:

`install.packages(c("mice", "factoextra", "gridExtra"))`

Considerando que `mice` será utilizada para la imputación de datos, `factoextra` para análisis factoriales, y `gridExtra` para la disposición gráfica.

Luego se añaden a la carga de las librerías a usar en el código:

```{r}
library("mice")
library("factoextra")
library("gridExtra")
library("tidyverse")
library("visdat")
library("dlookr")
library("e1071")
library("flextable") 
library("inspectdf") 
library("qqplotr") 
library("ggpmisc")
library("fdth")
library("PerformanceAnalytics")
library("corrplot")
```

# Carga de archivo y guardado en dataframe

Se inicia el trabajo de análisis de datos mediante la carga del archivo CSV, el cual se almacena en un dataframe llamado `air`, utilizando la función `read.csv()`. 

```{r}
air <- read.csv("/Users/nicolelastraquiroz/Documents/R studio/airq_dt.csv", header = T, sep = ",", dec = "." )
head(air)
```

Con esto ya se pueden apreciar algunas partes de la estructura básica del dataframe, como nombres de columnas y algunas filas de datos, sin embargo, en la busqueda de lo específico y prolijo, a continuación se procederá a hacer un análisis con más detalle.

## Análisis de la estructura del data frame

```{r}
dim(air)
str(air)
```

En general, se puede observar que el dataframe air contiene 100 observaciones (filas), correspondientes a 6 variables (columnas) del tipo numéricas (5 int y 1 num para ser específicos).

# Estudio de valores faltantes

Es importante destacar que la presencia de NA pueden interferir con los análisis posteriores, por lo que no se pueden dejar de considerar al momento de realizar estudios y observaciones primarias del dataframe, de ahí la importancia de generar imputaciones coherentes y adecuadas al set de datos trabajado.

En este caso, si bien ya se veían valores faltantes (NA) en la revisión anterior del dataframe, ahora se utilizará `summary()` para obtener un conteo rápido y verificar si hay valores nulos en el dataset (considerando que inicialmente se toman las 6 variables como numéricas, tal y como se pudo ver en la revisión anterior).

```{r}
summary(air)
```

Como complemento a esto, y considerando otras formas que también vimos en clases, se añade una revisión detallada usando el conteo por columna de los NA con `colSums(is.na())`.
 
```{r}
colSums(is.na(air))
```

Y también una visualización gráfica de los valores nulos con `visdat::vis_miss()`.

```{r}
visdat::vis_miss(air) 
```

De los 3 métodos expuestos, se puede afirmar que sí existen columnas con datos NA, estas son: `Ozono` y `RadSol`, con 18 y 4 valores faltantes respectivamente, lo que hace un total de un 3.7% de datos faltantes versus un 96,3% de datos válidos.

# Imputación de valores faltantes

Los valores faltantes se podrían imputar usando la media de cada variable, ya que esta es una estrategia simple y efectiva cuando el porcentaje de datos faltantes es bajo, como en este caso, sin embargo, y considerando aplicar al máximo lo visto en clases, utilizaremos la librería `mice`: *Multivariable Imputation by Chained Equations*, que ofrece un método destacado y altamente efectivo para la mayoría de los casso a imputar.

```{r}
imp_dt <- mice(air, m = 1, seed = 100)
air_impt <- complete(imp_dt, 1)
```

El resultado de la imputación fue almacenado en un nuevo dataframe denominado `air_impt`. 

# Verificación de valores faltantes

Para descartar cualquier posible error humano en el proceso de imputación (error de código, mal guardado de los datos imputados, entre otros), se revisará nuevamente la presencia de NA en la data y se generará una breve comparativa.

```{r}
colSums(is.na(air_impt))
```

**Antes de la imputación:**
```{r}
str(air)
```

**Después de la imputación:**
```{r}
str(air_impt)
```

En síntesis, se confirma que no existen datos faltantes posterior al proeso de imputación, por lo que hora se podrá implementar el resto de los análisis requeridos.

# Diagnóstico completo de las variables categóricas.

Aunque el dataset parece contener principalmente variables numéricas, Mes y Día pueden tratarse como variables categóricas dado su contexto, debido a esto, en este caso primero las transformaremos a categorías, y luego las analizaremos como tal. 

## Transformación de las variables Mes y Dia a categóricas.

```{r}
air_impt$Mes<-factor(air_impt$Mes)
air_impt$Dia<-factor(air_impt$Dia)
```

## Revisión de la transformación

```{r}
str(air_impt)
```

## Visualiación gráfica de los tipos de datos

```{r, fig.width = 5, fig.height = 3}
visdat::vis_dat(air_impt,sort_type = TRUE) 
```

## Análisis de las variables categóricas

```{r}
ft1 <- flextable(diagnose_category(air_impt))
ft1 <- set_caption(ft1, caption = "Detalle de variables categóricas")
ft1
```

# Estudio de normalidad en variables cuantitativas

```{r}

numeric_vars <- select_if(air_impt, is.numeric)
summary(numeric_vars)

```

## Análisis por método gráfico

### Histograma de frecuencias con abline de media y mediana

Para analizar las variables numéricas (Ozono, RadSol, Vient, Temp), se utilizarán histogramas. Éstos ayudan a visualizar la distribución de los datos y permiten, desde lo visual, identificar si las variables siguen una distribución simétrica o están sesgadas.

```{r}
plots <- list()

for (col in colnames(numeric_vars)) {
  mean_val <- mean(numeric_vars[[col]], na.rm = TRUE)
  median_val <- median(numeric_vars[[col]], na.rm = TRUE)
  
  p <- ggplot(numeric_vars, aes_string(x = col)) + 
        geom_histogram(binwidth = 10, fill = "pink", color = "black") +
        geom_vline(xintercept = mean_val, color = "blue", linetype = "dashed", size = 1) +
        geom_vline(xintercept = median_val, color = "magenta", linetype = "dashed", size = 1) +
        ggtitle(paste("Histograma de", col))
  
  plots[[col]] <- p
}

n_col <- 2

do.call("grid.arrange", c(plots, ncol = n_col))

```

Además, se añadieron líneas verticales que indican la media (en azul) y la mediana (en magenta) para cada variable, lo que facilita la comparación entre ambas medidas y ayuda a identificar la presencia de asimetría. Se debe destacar, que si la media y la mediana están muy alejadas, es probable que la distribución sea asimétrica, como son el caso de la variables `Ozono` y `RadSol`.

### Grafico de distribución de probabilidad normal

Primero usamos los recursos auxiliares aprendidos en clases para generar las tablas de frecuencias:

```{r}
tb.freq <- function(x){
  f_i <- as.vector(table(x)) # freq absoluta
  F_i <- cumsum(f_i) # freq acumulada
  h_i <- f_i / length(x) # freq relativa
  H_i <- F_i / length(x) # freq relativa acumulada
  tf <- cbind(f_i, F_i, h_i, H_i)
  row.names(tf) <- names(table(x))
  tf
}

```

Luego, con la función ya creada, generamos las tablas de frecuencias usando sturges. También se definirán los intervalos, se generarán los cortes y agrupaciones y finalmente se visualizarán las tablas.

```{r}
# Tablas de distribución de frecuencias 
for (var_name in colnames(numeric_vars)) {
  print(paste("Tabla de distribución de frecuencias para:", var_name))
  tabla <- fdt(numeric_vars[[var_name]], breaks = "Sturges")
  print(tabla)
  
  # Calculo del intervalo
  intervalo <- (max(numeric_vars[[var_name]]) - min(numeric_vars[[var_name]])) / (1 + 3.322 * log10(nrow(numeric_vars)))
  print(paste("Intervalo calculado para", var_name, ":", intervalo))
  
  # Cortes y agrupación de los datos
  cut_var <- cut(numeric_vars[[var_name]], breaks = seq(min(numeric_vars[[var_name]]), max(numeric_vars[[var_name]]), by = intervalo))
  numeric_vars[[paste(var_name, "cut", sep = ".")]] <- cut_var

  # Tabla de frecuencias
  print(tb.freq(cut_var))
}
```

Finalmente se procederá con la genración de los gráficos de densidad normal y de probabilidad acumulada normal, para cada una de las variables numéricas.

```{r, fig.width = 6, fig.height = 10}

par(mfrow = c(4, 2))
for (var_name in colnames(numeric_vars)[1:4]) {
  
# Gráfico de densidad vs distribución normal
  plot(numeric_vars[[var_name]], 
       dnorm(numeric_vars[[var_name]], 
             mean = mean(numeric_vars[[var_name]],
                         na.rm = TRUE), 
             sd = sd(numeric_vars[[var_name]],
                     na.rm = TRUE)),
       ylab = "",xlab = var_name, 
       lwd = 2, col = "pink", main = paste("Densidad normal: ", var_name))
  
# Gráfico de probabilidad acumulada vs distribución normal
  plot(numeric_vars[[var_name]], 
       pnorm(numeric_vars[[var_name]], 
             mean = mean(numeric_vars[[var_name]],
                         na.rm = TRUE), 
             sd = sd(numeric_vars[[var_name]],
                     na.rm = TRUE)),
       xlab = var_name, ylab = "", 
       lwd = 2, col = "pink", 
       main = paste("P(x) acumulada normal: ",
                    var_name))
  
# Media y mediana como líneas verticales
  abline(v = mean(numeric_vars[[var_name]], 
                  na.rm = TRUE), col = "magenta")
  abline(v = median(numeric_vars[[var_name]], 
                    na.rm = TRUE), col = "blue")
}

```


## Análisis por método matemático:

A continuación, se complementa el análisis gráfico con un enfoque matemático, para lo cual se definirán las hipótesis, se calculará la asimetría (`skewness`) y la curtosis (`kurtosis`) de cada variable.

### Formulación de hipótesis

Primero se establece las respectivas hipótesis del caso: 

* $H_0:$ La variable está distribuida normalmente.

* $H_1:$ La variable no está distribuida normalmente.

Se considera una significancia del 0.05, lo que implica que si el valor p es mayor a este valor, no se rechazará la hipótesis nula y, por lo tanto, se puedodría afirmar que la variable está distribuida normalmente.

### Test de Shapiro-Wilk

se realiza la prueba de Shapiro-Wilk para evaluar la normalidad de cada variable. Esta prueba es estadísticamente robusta para tamaños de muestra pequeños, como es este caso. 

```{r}

for (col in colnames(air_impt)[1:4]) {
  cat("\nVariable:", col)
  cat("\nPrueba de Shapiro-Wilk:\n")
  print(shapiro.test(air_impt[[col]]))
}
```


### Resumen de normalidad para las variabes numéricas

```{r}
ft2 <- flextable(normality(numeric_vars))
ft2 <- set_caption(ft2, caption = "Tabla de Normalidad por variables")

ft2
```

### Cesgo

Se debe tener en cuenta que `skewness` mide la simetría de la distribución. Los valores cercanos a 0 indicarán que la distribución de los datos es bastante simétrica.

```{r}

for (col in colnames(air)[1:4]) {
  cat("\nVariable:", col)
  cat("\nSkewness:", skewness(air_impt[[col]], na.rm = TRUE))
}
```

Ozono es la variable que mas presenta cesgo, considerando que posee un Skewness del orden de 1.26 aproximadamente. Las otras variables presentan cesgos bajos y en un orden parecido (al rededor del 0.3), sólo que para Vient es del tipo positivo y para RadSol y Temp es negativo.

### Curtosis

La curtosis mide la "altura" y "anchura" de las colas de la distribución. Una curtosis positiva indica colas más pesadas que las de una distribución normal, mientras que una curtosis negativa indica colas más ligeras que las de una distribución normal.

**Aquí falta añadir algo de datos bibliográficos que tengan cita en APA para decir los tipos de de curtosis si es menor a cero igual o mayor... onda platicurtica, mesocurtica y leptocurtica**

```{r}

for (col in colnames(air_impt)[1:4]) {
  cat("\nVariable:", col)
  cat("\nKurtosis:", kurtosis(air_impt[[col]], na.rm = TRUE))
}
```

Se observan tendencias platicurticas en las variables RadSol, Vient y Temp, siendo la primera la que posee una tendencia más marcada que las otras, mientras que en el caso de Ozono su tendencia es del tipo leptocurtica. 

# Estudio de valores atípicos (outliers)

Los boxplots permiten identificar valores atípicos (outliers) que se representan como puntos fuera de los "bigotes" del gráfico.

```{r, fig.width = 6, fig.height = 4}

par(mfrow = c(2, 2))
boxplot(air_impt$Ozono, main = "Boxplot de Ozono", col = "lightblue", horizontal = TRUE)
boxplot(air_impt$RadSol, main = "Boxplot de RadSol", col = "lightpink", horizontal = TRUE)
boxplot(air_impt$Vient, main = "Boxplot de Viento", col = "lightgrey", horizontal = TRUE)
boxplot(air_impt$Temp, main = "Boxplot de Temperatura", col = "lightyellow", horizontal = TRUE)
```

Mediante los diagramas "boxplot" se puede evidenciar visualmente la existencia de "outliers" en las variables Ozono y viento, pero para un estudio preciso, revisaremos el detalle de estos valores atípicos con la función `flextable(diagnose_outlier())`, como se muestra a continuación:

```{r}
ft3 <- flextable::flextable(diagnose_outlier(air_impt))
ft3 <- set_table_properties(ft3, width = 0.75, layout = "autofit")
ft3 <- align(ft3, align = "center", part = "all")
ft3 <- set_caption(ft3, caption = "Detalles de valores atípicos en las variables")

ft3
```

Ahora se cuenta con una mayor cantidad de información concreta respecto a estos valores atípicos, considerando por ejemplo el número y la media de éstos: 

* Ozono: 1 valor atípico con una media de 168
* Vient: 2 valores atípicos con una media de 20.4

Este tipo de información es altamente importante para una posterior toma de decisiones respecto a si eliminar o no estos valores, entre otras posibles acciones a realizar.

